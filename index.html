<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>CodePen - MediaPipe HandLandmarker Task for web</title>
  <link rel="stylesheet" href="./style.css" />
</head>
<style>
  @font-face {
    font-family: "Asflat";
    src: url("font/Asflat.woff2") format("woff2");
  }

  body {
    margin: 0;
    padding: 0;
    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;
    height: 100vh;
    font-family: "Asflat", sans-serif;
  }

  #handStatus {
    font-size: 400px;
    text-align: center;
    margin: 0;
  }
</style>
<script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
<script src="https://unpkg.com/tone@14.8.49/build/Tone.js"></script>

<body>
  <div id="liveView" class="videoView">
    <button id="webcamButton" class="mdc-button mdc-button--raised">
      <span class="mdc-button__ripple"></span>
      <span class="mdc-button__label">ENABLE WEBCAM</span>
    </button>
    <p id="handStatus"></p>
    <div style="position: relative">
      <!-- Video element is hidden by setting its display to none -->
      <video id="webcam" style="display: none" autoplay playsinline></video>
      <canvas
        class="output_canvas"
        id="output_canvas"
        style="display: none; position: absolute; left: 0px; top: 0px"
      ></canvas>
    </div>
  </div>

  <!-- partial -->
  <script type="module">
    import { HandLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    const demosSection = document.getElementById("demos");
    let handLandmarker = undefined;
    let runningMode = "IMAGE";
    let enableWebcamButton;
    let webcamRunning = false;
    let results = undefined;

    // Tone.js Audio Players
    const onPlayer = new Tone.GrainPlayer({
      "url": "sound/on.mp3",
      "loop": true


    }).toDestination();

    const andPlayer = new Tone.GrainPlayer({
      "url": "sound/and.mp3",
      "loop": true,
      "grainSize": 0.1,

    }).toDestination();

    // Before we can use HandLandmarker class we must wait for it to finish
    // loading. Machine Learning models can be large and take a moment to
    // get everything needed to run.
    const createHandLandmarker = async () => {
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
      );
      handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`,
          delegate: "GPU",
        },
        runningMode: runningMode,
        numHands: 1,
      });
      // demosSection.classList.remove("invisible");
    };

    createHandLandmarker();

    const video = document.getElementById("webcam");
    const canvasElement = document.getElementById("output_canvas");
    const canvasCtx = canvasElement.getContext("2d");

    // Check if webcam access is supported.
    const hasGetUserMedia = () => {
      var _a;
      return !!((_a = navigator.mediaDevices) === null || _a === void 0
        ? void 0
        : _a.getUserMedia);
    };

    // If webcam supported, add event listener to button for when user
    // wants to activate it.
    if (hasGetUserMedia()) {
      enableWebcamButton = document.getElementById("webcamButton");
      enableWebcamButton.addEventListener("click", enableCam);
    } else {
      console.warn("getUserMedia() is not supported by your browser");
    }

    // Enable the live webcam view and start detection.
    function enableCam(event) {
      if (!handLandmarker) {
        console.log("Wait! objectDetector not loaded yet.");
        return;
      }

      if (webcamRunning === true) {
        webcamRunning = false;
        enableWebcamButton.innerText = "ENABLE PREDICTIONS";
      } else {
        webcamRunning = true;
        enableWebcamButton.innerText = "DISABLE PREDICTIONS";
      }

      // Remove the enable webcam button from the DOM
      enableWebcamButton.remove();

      // getUsermedia parameters.
      const constraints = {
        video: true,
      };

      // Activate the webcam stream.
      navigator.mediaDevices.getUserMedia(constraints).then((stream) => {
        video.srcObject = stream;
        video.addEventListener("loadeddata", predictWebcam);
      });
    }

    let lastVideoTime = -1;

    async function predictWebcam() {
      // Ensure the canvas dimensions match the video dimensions.
      canvasElement.style.width = video.videoWidth + "px";
      canvasElement.style.height = video.videoHeight + "px";
      canvasElement.width = video.videoWidth;
      canvasElement.height = video.videoHeight;

      // Switch to 'VIDEO' mode if necessary.
      if (runningMode === "IMAGE") {
        runningMode = "VIDEO";
        await handLandmarker.setOptions({ runningMode: "VIDEO" });
      }

      if (lastVideoTime !== video.currentTime) {
        lastVideoTime = video.currentTime;
        results = await handLandmarker.detectForVideo(
          video,
          performance.now()
        ); // Await detection.
      }

      // Clear the canvas for the new frame.
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);

      // If hand landmarks are detected...
      if (results && results.landmarks && results.landmarks.length > 0) {
        const landmarks = results.landmarks[0]; // Assuming there's only one hand detected.
        const wristLandmark = landmarks[0]; // Assuming the first landmark is the wrist.

        // Calculate font width based on the wrist's x-coordinate.
        // Assuming wristLandmark.x is normalized between 0 and 1.
        let fontWidthValue;
        if (wristLandmark.x <= 0.5) {
          // Map 0 to 0.5 to font width from 100 to 50
          fontWidthValue = 100 - wristLandmark.x * 100; // 100 - (0 to 0.5) * 100
        } else {
          // Map 0.5 to 1 to font width from 50 to 100
          fontWidthValue = 50 + (wristLandmark.x - 0.5) * 100; // 50 + (0 to 0.5) * 100
        }

        // Calculate font weight based on the wrist's y-coordinate.
        // Assuming wristLandmark.y is normalized between 0 and 1.
        const fontWeightValue = 300 + wristLandmark.y * 400; // 300 + (0 to 1) * 400

        // Update the body's font variation settings directly.
        document.body.style.fontVariationSettings = `'wdth' ${fontWidthValue}, 'wght' ${fontWeightValue}`;

        // Map x-position to playback rate
        const playbackRate = mapValue(fontWidthValue, 50, 100, 10, 0);

        // Map y-position to grainSize value
const grainSizeValue = mapValue(wristLandmark.y, 0, 1, 1, 0.05);

// Set the grainSize of the audio players
onPlayer.grainSize = grainSizeValue;
andPlayer.grainSize = grainSizeValue;

        // Set the playback rate of the audio players
        onPlayer.playbackRate = playbackRate;
        andPlayer.playbackRate = playbackRate;

        console.log("playbackRate", playbackRate);
        // Determine which side of the screen the hand is on
        const handStatusElement = document.getElementById("handStatus");
        if (wristLandmark.x < 0.5) {
          handStatusElement.textContent = "on";
          document.body.style.backgroundColor = "black";
          document.getElementById("handStatus").style.color = "white";
          if (!onPlayer.state.startsWith("started")) {
            onPlayer.start();
          }
          andPlayer.stop();
        } else {
          document.body.style.backgroundColor = "white";
          document.getElementById("handStatus").style.color = "black";
          handStatusElement.textContent = "and";
          if (!andPlayer.state.startsWith("started")) {
            andPlayer.start();
          }
          onPlayer.stop();
        }

        // Visualization: draw the detected landmarks and connections on the canvas.
        drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS, {
          color: "#00FF00",
          lineWidth: 5,
        });
        drawLandmarks(canvasCtx, landmarks, {
          color: "#FF0000",
          lineWidth: 2,
        });
      }

      canvasCtx.restore();

      // Continue predicting if the webcam is still running.
      if (webcamRunning === true) {
        window.requestAnimationFrame(predictWebcam);
      }
    }

    // Map value function
    function mapValue(value, minInput, maxInput, minOutput, maxOutput) {
      return minOutput + (maxOutput - minOutput) * ((value - minInput) / (maxInput - minInput));
    }

    document.addEventListener("DOMContentLoaded", function () {
      Tone.start(); // Ensure audio context is resumed
    });
  </script>
</body>
</html>
